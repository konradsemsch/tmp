penalty(),
mixture(),
size = 3,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid
# metrics = metric_set(roc_auc),
# control = control_grid(verbose = TRUE) # add paralell procecessing at a later stage
)
tuning$.notes[[1]]
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glm")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 3,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid
# metrics = metric_set(roc_auc),
# control = control_grid(verbose = TRUE) # add paralell procecessing at a later stage
)
library(modeldata)
library(tidymodels)
library(tidyverse)
library(magrittr)
data("okc")
colnames(okc) <- tolower(names(okc))
okc <- sample_n(okc, 1000)
strata <- "class"
split <- initial_split(okc, prop = 0.8, strata = strata)
train <- training(split)
test <- testing(split)
###  Different ways to do data splitting ###
# Regular cross-validation
cv <- vfold_cv(
train,
v = 5,
repeats = 1,
strata = strata
)
# Bootstrap
bs <- bootstraps(
train,
times = 25,
strata = strata
)
# Leave-one-out cross validation
# Nested cross-validation - I will need to do this in a custom way
# You can add that at a later stage
cv_nested <- nested_cv(
train,
outside = cv,
inside = bootstraps(times = 20, strata = strata)
)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_BoxCox(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes()) %>%
# Time predictors
step_date(date)
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glm")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 20,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid
# metrics = metric_set(roc_auc),
# control = control_grid(verbose = TRUE) # add paralell procecessing at a later stage
)
grid
cv
training(cv$splits)
training(cv$splits[[1]])
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 20,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid
# metrics = metric_set(roc_auc),
# control = control_grid(verbose = TRUE) # add paralell procecessing at a later stage
)
juice(prep(recipe)) %>% glimpse()
?step_date
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_BoxCox(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
# Time predictors
step_date(date) %>%
step_rm(date) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes())
juice(prep(recipe)) %>% glimpse()
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glm")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 20,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE) # add paralell procecessing at a later stage
)
train %>% glimpse()
cv_nested <- nested_cv(
train,
outside = cv,
inside = bootstraps(times = 20, strata = strata)
)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_BoxCox(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
# Time predictors
step_date(date) %>%
step_rm(date) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes()) %>%
prep()
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 20,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE) # add paralell procecessing at a later stage
)
library(modeldata)
library(tidymodels)
library(tidyverse)
library(magrittr)
data("okc")
colnames(okc) <- tolower(names(okc))
okc <- sample_n(okc, 1000)
strata <- "class"
split <- initial_split(okc, prop = 0.8, strata = strata)
train <- training(split)
test <- testing(split)
cv <- vfold_cv(
train,
v = 5,
repeats = 1,
strata = strata
)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_BoxCox(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
# Time predictors
step_date(date) %>%
step_rm(date) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes())
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 10,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
juice(prep(recipe)) %>% glimpse()
all_predictors()
?all_predictors()
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome")
recipe
current_info()
sessionInfo()
library(modeldata)
library(tidymodels)
library(tidyverse)
library(magrittr)
data("okc")
colnames(okc) <- tolower(names(okc))
okc <- sample_n(okc, 1000)
strata <- "class"
split <- initial_split(okc, prop = 0.8, strata = strata)
train <- training(split)
test <- testing(split)
cv <- vfold_cv(
train,
v = 5,
repeats = 1,
strata = strata
)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_BoxCox(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
# Time predictors
step_date(date) %>%
step_rm(date) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes())
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 10,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
glimpse(train)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") # %>%
#
# # Numeric predictors
# step_medianimpute(all_numeric(), all_predictors()) %>%
# step_BoxCox(all_numeric(), all_predictors()) %>%
# step_normalize(all_numeric(), all_predictors()) %>%
#
# # Categorical predictors
# step_modeimpute(all_nominal(), all_predictors()) %>%
#
# # Time predictors
# step_date(date) %>%
# step_rm(date) %>%
#
# step_dummy(all_nominal(), all_predictors(), -all_outcomes())
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 10,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
model <- logistic_reg(
penalty = 0.01, #tune(),
mixture = 0.5, # tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
fit <- fit(workflow, train)
model <- logistic_reg(
# penalty = tune(),
# mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
fit <- fit(workflow, data = train)
glimpse(train)
model <- logistic_reg(
# penalty = tune(),
# mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glm")
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
fit <- fit(workflow, data = train)
sessionInfo()
model <- logistic_reg(
# penalty = tune(),
# mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
fit <- fit(workflow, data = train)
library(modeldata)
library(tidymodels)
library(tidyverse)
library(magrittr)
data("okc")
colnames(okc) <- tolower(names(okc))
okc <- sample_n(okc, 1000)
strata <- "class"
split <- initial_split(okc, prop = 0.8, strata = strata)
train <- training(split)
test <- testing(split)
cv <- vfold_cv(
train,
v = 5,
repeats = 1,
strata = strata
)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
# Time predictors
step_date(date) %>%
step_rm(date) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes())
model <- logistic_reg(
# penalty = tune(),
# mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 10,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
fit <- fit(workflow, data = train)
library(modeldata)
library(tidymodels)
library(tidyverse)
library(magrittr)
data("okc")
colnames(okc) <- tolower(names(okc))
okc <- sample_n(okc, 1000)
strata <- "class"
split <- initial_split(okc, prop = 0.8, strata = strata)
train <- training(split)
test <- testing(split)
cv <- vfold_cv(
train,
v = 5,
repeats = 1,
strata = strata
)
recipe <- train %>%
recipe() %>%
update_role(strata, new_role = "outcome") %>%
# Numeric predictors
step_medianimpute(all_numeric(), all_predictors()) %>%
step_normalize(all_numeric(), all_predictors()) %>%
# Categorical predictors
step_modeimpute(all_nominal(), all_predictors()) %>%
# Time predictors
step_date(date) %>%
step_rm(date) %>%
step_dummy(all_nominal(), all_predictors(), -all_outcomes())
model <- logistic_reg(
penalty = tune(),
mixture = tune()
) %>%
set_mode("classification") %>%
set_engine("glmnet")
grid <- grid_max_entropy(
penalty(),
mixture(),
size = 10,
variogram_range = 1
)
workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(model)
# fit <- fit(workflow, data = train)
tuning <- tune_grid(
workflow,
resamples = cv,
grid = grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
juice(prep(recipe)) %>% glimpse()
tuning$.notes[[1]]
install.packages("prompt")
devtools::install_github("https://github.com/gaborcsardi/prompt")
library(prompt)
set_prompt(prompt_fancy)
ksndn
clear
print("hello")
